{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Description sentiment and image processing.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Reading data",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import pearsonr\nfrom PIL import Image",
      "execution_count": 7,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_json('../input/train.json')\ndf.info()",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 49352 entries, 10 to 99994\nData columns (total 15 columns):\nbathrooms          49352 non-null float64\nbedrooms           49352 non-null int64\nbuilding_id        49352 non-null object\ncreated            49352 non-null object\ndescription        49352 non-null object\ndisplay_address    49352 non-null object\nfeatures           49352 non-null object\ninterest_level     49352 non-null object\nlatitude           49352 non-null float64\nlisting_id         49352 non-null int64\nlongitude          49352 non-null float64\nmanager_id         49352 non-null object\nphotos             49352 non-null object\nprice              49352 non-null int64\nstreet_address     49352 non-null object\ndtypes: float64(3), int64(3), object(9)\nmemory usage: 6.0+ MB\n"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# scale price for a plot\ndf['price'] = df['price']/1000.\ng = sns.pairplot(df[['price','interest_level','bedrooms',\\\n                 'bathrooms']], hue=\"interest_level\",size=2)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Looks like price has few extremes, let's eliminate those to have a better picture.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.price.describe([0,0.75,0.98,0.99])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# 98% of listings fall under a price of 10k\ng = sns.pairplot(df.ix[df.price<10,['price','interest_level','bedrooms',\\\n                 'bathrooms']], hue=\"interest_level\",size=2)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Overall no surprises here, tolerance for higher price moves higher as the number of bedrooms and bathrooms increases. Let's look at bathrooms in a bit more details.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.hist(by='interest_level',column = 'bathrooms',align='mid',sharex=True,\\\n        bins=10,layout=(3,1),figsize=(7,9))\nplt.xticks(np.arange(1,11))\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.groupby('interest_level').bathrooms.value_counts()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "It does not look like the number of bathrooms is important. Let's check the correlation coefficient.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(pearsonr(df.interest_level.astype('category').cat.codes,df.bathrooms)[0])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Indeed it is not. Let's look at the apartment features now. First let's start with the number of the features.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Description sentiment",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.tokenize import sent_tokenize",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def description_sentiment(sentences):\n    analyzer = SentimentIntensityAnalyzer()\n    result = []\n    for sentence in sentences:\n        vs = analyzer.polarity_scores(sentence)\n        result.append(vs)\n    return pd.DataFrame(result).mean()\n\ndf['description_tokens'] = df['description'].apply(sent_tokenize)\ndf = pd.concat([df,joint['description_tokens'].apply(description_sentiment)],axis=1)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Photo properties",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's also explore the possible correlations between features and simple high-level properties of images without going into NN. Let's look at the number of images, image size, brightness, hue and saturation.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get available images\nfrom subprocess import check_output\nimages = [int(x) for x in check_output([\"ls\", \"../input/images_sample\"]).decode(\"utf8\").strip().split('\\n')]\n\n# Read the train set and choose those which have images only\ndf = df[df.listing_id.isin(images)]\nprint(df.shape)\n\n# Add number of images\ndf['n_images'] = df.apply(lambda x: len(x['photos']), axis=1)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# this is what we are after\ncheck_output([\"ls\", \"../input/images_sample/6812223\"]).decode(\"utf8\").strip().split('\\n')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#function to process one image\ndef process_image(path):\n    path = '../input/images_sample/'+path[0:7]+'/'+path\n    im = np.array(Image.open(path))\n\n    #get dims\n    width = im.shape[1]\n    height = im.shape[0]\n    \n    #flatten image\n    im = im.transpose(2,0,1).reshape(3,-1)\n   \n    \n    #brightness is simple, assign 1 if zero to avoid divide\n    brg = np.amax(im,axis=0)\n    brg[brg==0] = 1\n    \n    #hue, same, assign 1 if zero, not working atm due to arccos\n    denom = np.sqrt((im[0]-im[1])**2-(im[0]-im[2])*(im[1]-im[2]))\n    denom[denom==0] = 1\n    #hue = np.arccos(0.5*(2*im[0]-im[1]-im[2])/denom)\n    \n    #saturation\n    sat = (brg - np.amin(im,axis=0))/brg\n    \n    #return mean values\n    return width,height,np.mean(brg),np.mean(sat)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#second helper function - process a row of a dataset\n#return mean of each property for all images\ndef process_row(row):\n    images = check_output([\"ls\", \"../input/images_sample/\"+str(row.listing_id)]).decode(\"utf8\").strip().split('\\n')\n    res = np.array([process_image(x) for x in images])\n    res = np.mean(res,axis=0)\n    row['img_width'] = res[0]\n    row['img_height'] = res[1]\n    row['img_brightness'] = res[2]\n    row['img_saturation'] = res[3]\n    return row",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Now we can process the dataset\ndf = df.apply(lambda row: process_row(row),axis=1)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Some plots\nd = df[['img_width','n_images','img_height','img_brightness','img_saturation','interest_level']]\nsns.pairplot(d, hue=\"interest_level\",size=1.5)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Looks like it is all over the place, so it is unlikely to be a good feature. It is easy to calculate so perhaps still worth a try on a full image dataset.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}